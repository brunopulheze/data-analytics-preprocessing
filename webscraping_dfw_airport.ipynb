{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f872d132",
   "metadata": {},
   "source": [
    "# Webscraping and Statistical Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5159c6b7",
   "metadata": {},
   "source": [
    "### Webscraping Dallas Fort Worth Airport (DFW) for flight delays on 2025-10-07 and comparing with historical data from 2024-10-09"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2d46dc",
   "metadata": {},
   "source": [
    "Find the city with most departure delays in order to webscrape its airport website for delay information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33a5eb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbca7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver = webdriver.Chrome()\n",
    "# driver.get(\"https://www.dfwairport.com/flights/\")\n",
    "# wait = WebDriverWait(driver, 10)\n",
    "\n",
    "# input(\"Please click 'Departures' and 'Show Earlier Flights' until ready, then press Enter to start scraping...\")\n",
    "\n",
    "data = []\n",
    "\n",
    "while True:\n",
    "    rows = driver.find_elements(By.CSS_SELECTOR, 'div.css-16mp7cl.e1tlh5vk0')\n",
    "    for row in rows:\n",
    "        try:\n",
    "            status_div = row.find_element(By.CSS_SELECTOR, 'div.css-1tdn8t0.e1xvvp7d0')\n",
    "            status_span = status_div.find_element(By.CSS_SELECTOR, 'span.e1y53rij0')\n",
    "            status_text = status_span.text.strip()\n",
    "            times_div = row.find_element(By.CSS_SELECTOR, 'div.css-1c5a36w.e8j8o0n0')\n",
    "            s_tags = times_div.find_elements(By.TAG_NAME, 's')\n",
    "            em_tags = times_div.find_elements(By.TAG_NAME, 'em')\n",
    "            span_tags = times_div.find_elements(By.TAG_NAME, 'span')\n",
    "\n",
    "            if status_text in [\"Departed\", \"Delayed\"]:\n",
    "                if s_tags and em_tags:\n",
    "                    expected_dep = s_tags[0].text.strip()\n",
    "                    dep_delay = em_tags[0].text.strip()\n",
    "                elif span_tags:\n",
    "                    expected_dep = span_tags[0].text.strip()\n",
    "                    dep_delay = \"\"\n",
    "                else:\n",
    "                    expected_dep = times_div.text.strip()\n",
    "                    dep_delay = \"\"\n",
    "                data.append({\n",
    "                    \"expected_dep\": expected_dep,\n",
    "                    \"dep_delay\": dep_delay\n",
    "                })\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    try:\n",
    "        earlier_btn = driver.find_element(By.CSS_SELECTOR, 'button.css-1ug2c5u.e1owxzay2')\n",
    "        if earlier_btn.is_enabled() and 'Show earlier flights' in earlier_btn.text:\n",
    "            earlier_btn.click()\n",
    "            wait.until(EC.staleness_of(rows[0]))\n",
    "            wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'div.css-16mp7cl.e1tlh5vk0')))\n",
    "        else:\n",
    "            break\n",
    "    except Exception:\n",
    "        break\n",
    "\n",
    "driver.quit()\n",
    "print(\"Scraping complete.\")\n",
    "\n",
    "# Create DataFrame\n",
    "df_scraped = pd.DataFrame(data, columns=[\"expected_dep\", \"dep_delay\"])\n",
    "\n",
    "# Assign date column: before 00:00 AM is 2025-10-07, at/after 00:00 AM is 2025-10-08\n",
    "def assign_date(time_str):\n",
    "    if pd.isna(time_str) or str(time_str).strip() == '':\n",
    "        return pd.NaT\n",
    "    dt = pd.to_datetime(time_str, format='%I:%M %p', errors='coerce')\n",
    "    if pd.isna(dt):\n",
    "        return pd.NaT\n",
    "    if dt.hour == 0 and dt.minute == 0:\n",
    "        return \"2025-10-08\"\n",
    "    return \"2025-10-07\"\n",
    "\n",
    "df_scraped['date'] = df_scraped['expected_dep'].apply(assign_date)\n",
    "\n",
    "# Convert expected_dep and dep_delay to minutes since midnight\n",
    "def time_to_minutes(timestr):\n",
    "    if pd.isna(timestr) or str(timestr).strip() == '':\n",
    "        return None\n",
    "    try:\n",
    "        dt = pd.to_datetime(timestr, format='%I:%M %p', errors='coerce')\n",
    "        if pd.isna(dt):\n",
    "            return None\n",
    "        return dt.hour * 60 + dt.minute\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "df_scraped['expected_dep_min'] = df_scraped['expected_dep'].apply(time_to_minutes)\n",
    "df_scraped['dep_delay_min'] = df_scraped['dep_delay'].apply(time_to_minutes)\n",
    "\n",
    "# Final output: ONLY expected_dep_min, dep_delay_min, and date\n",
    "df_scraped = df_scraped[[\"expected_dep_min\", \"dep_delay_min\", \"date\"]]\n",
    "\n",
    "df_scraped.to_csv('scraped_dfw_flights.csv', index=False)\n",
    "\n",
    "print(df_scraped.head())\n",
    "print(\"Scraping complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
